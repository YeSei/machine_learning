{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "def load_data():\n",
    "    iris = datasets.load_iris() #加载 iris 数据集\n",
    "    iris_feature = iris.data #特征数据\n",
    "    iris_target = iris.target #分类数据\n",
    "    labels = ['sepal length', 'sepal width', 'petal length', 'petal width'] # 定义标签\n",
    "    \n",
    "    # 划分训练集和测试集\n",
    "    feature_train, feature_test, target_train, target_test = train_test_split(iris_feature, iris_target, test_size=0.33, random_state=42)\n",
    "    \n",
    "    # 对训练集和测试集做简单处理，对连续float值转化为int处理，离散化连续变量\n",
    "    traindata = np.rint( np.column_stack((feature_train,target_train)) )\n",
    "    testdata = np.rint( np.column_stack((feature_test,target_test)) )\n",
    "    return traindata,testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_tags: [4.0, 5.0, 6.0, 7.0, 8.0]\n",
      "prob: 0.04\n",
      "prob: 0.32\n",
      "prob: 0.45\n",
      "prob: 0.15\n",
      "prob: 0.04\n",
      "iv: 1.8264887070850935\n",
      "feature_tags: [2.0, 3.0, 4.0]\n",
      "prob: 0.14\n",
      "prob: 0.73\n",
      "prob: 0.13\n",
      "iv: 1.1111974093459056\n",
      "feature_tags: [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0]\n",
      "prob: 0.17\n",
      "prob: 0.14\n",
      "prob: 0.03\n",
      "prob: 0.23\n",
      "prob: 0.24\n",
      "prob: 0.16\n",
      "prob: 0.03\n",
      "iv: 2.540049817564643\n",
      "feature_tags: [0.0, 1.0, 2.0]\n",
      "prob: 0.3\n",
      "prob: 0.28\n",
      "prob: 0.42\n",
      "iv: 1.5609563153489605\n",
      "feature_tags: [5.0, 6.0, 7.0]\n",
      "prob: 0.21428571428571427\n",
      "prob: 0.7142857142857143\n",
      "prob: 0.07142857142857142\n",
      "iv: 1.0949143184120975\n",
      "feature_tags: [2.0, 3.0, 4.0]\n",
      "prob: 0.32142857142857145\n",
      "prob: 0.6428571428571429\n",
      "prob: 0.03571428571428571\n",
      "iv: 1.107784384952517\n",
      "feature_tags: [2.0, 3.0, 4.0, 5.0, 6.0]\n",
      "prob: 0.03571428571428571\n",
      "prob: 0.10714285714285714\n",
      "prob: 0.6785714285714286\n",
      "prob: 0.14285714285714285\n",
      "prob: 0.03571428571428571\n",
      "iv: 1.469300984286476\n",
      "feature_tags: [8.0, 5.0, 6.0, 7.0]\n",
      "prob: 0.09523809523809523\n",
      "prob: 0.047619047619047616\n",
      "prob: 0.5476190476190477\n",
      "prob: 0.30952380952380953\n",
      "iv: 1.5316592959895816\n",
      "feature_tags: [2.0, 3.0, 4.0]\n",
      "prob: 0.09523809523809523\n",
      "prob: 0.8809523809523809\n",
      "prob: 0.023809523809523808\n",
      "iv: 0.6125608863913522\n",
      "feature_tags: [4.0, 5.0, 6.0, 7.0]\n",
      "prob: 0.09523809523809523\n",
      "prob: 0.47619047619047616\n",
      "prob: 0.35714285714285715\n",
      "prob: 0.07142857142857142\n",
      "iv: 1.6352505576826057\n",
      "feature_tags: [5.0, 6.0]\n",
      "prob: 0.5\n",
      "prob: 0.5\n",
      "iv: 1.0\n",
      "feature_tags: [2.0, 3.0]\n",
      "prob: 0.25\n",
      "prob: 0.75\n",
      "iv: 0.8112781244591328\n",
      "feature_tags: [6.0, 7.0]\n",
      "prob: 0.85\n",
      "prob: 0.15\n",
      "iv: 0.6098403047164004\n",
      "feature_tags: [2.0, 3.0]\n",
      "prob: 0.15\n",
      "prob: 0.85\n",
      "iv: 0.6098403047164004\n",
      "feature_tags: [2.0, 3.0]\n",
      "prob: 0.17647058823529413\n",
      "prob: 0.8235294117647058\n",
      "iv: 0.672294817075638\n",
      "{'feature': 3, 'children': {0.0: {'label': 0.0}, 1.0: {'feature': 2, 'children': {2.0: {'label': 0.0}, 3.0: {'label': 1.0}, 4.0: {'label': 1.0}, 5.0: {'label': 1.0}, 6.0: {'label': 2.0}}}, 2.0: {'feature': 2, 'children': {4.0: {'feature': 1, 'children': {2.0: {'label': 2.0}, 3.0: {'label': 1.0}}}, 5.0: {'feature': 0, 'children': {6.0: {'feature': 1, 'children': {2.0: {'label': 2.0}, 3.0: {'label': 2.0}}}, 7.0: {'label': 1.0}}}, 6.0: {'label': 2.0}, 7.0: {'label': 2.0}}}}}\n",
      "[1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 2.0, 2.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0]\n",
      "0.92\n"
     ]
    }
   ],
   "source": [
    "# 计算信息熵\n",
    "def get_entropy(dataset):\n",
    "    \n",
    "    #创建所有类别列表：\n",
    "    label_tags = list(set(dataset[:, -1]))\n",
    "    label_length = len(dataset[:, -1])\n",
    "    tmp_entropy = 0\n",
    "    \n",
    "    # 计算信息熵\n",
    "    for label_tag in label_tags:\n",
    "        tmp = sum([1 for d in dataset if d[-1]==label_tag])\n",
    "        prob = tmp/label_length\n",
    "        tmp_entropy += (prob)*np.math.log(prob, 2)\n",
    "    entropy = -tmp_entropy\n",
    "    return entropy\n",
    "\n",
    "#计算某特征分类后的信息增益率\n",
    "def get_rela_entropy(dataset, feature:int):\n",
    "    \n",
    "    # 生成某特征的取值范围\n",
    "    feature_tags = list(set(dataset[:, feature]))\n",
    "    print(\"feature_tags:\",feature_tags)\n",
    "    sub_entropy = 0.0\n",
    "    iv = 0.0\n",
    "    \n",
    "    # 计算某个特征值的信息增益\n",
    "    for feature_tag in feature_tags:\n",
    "        sub_dataset = [d for d in dataset if d[feature]==feature_tag]\n",
    "        sub_dataset = np.array(sub_dataset)\n",
    "        \n",
    "        # 计算某特征值的信息熵\n",
    "        tmp_entropy = get_entropy(sub_dataset)\n",
    "        \n",
    "        # 计算每个结点的类别权重：\n",
    "        prob = float(len(sub_dataset)/len(dataset))\n",
    "        print(\"prob:\",prob)\n",
    "        iv -= float(prob*np.math.log(prob, 2))\n",
    "        \n",
    "        \n",
    "        # 计算分类后带权值的信息熵总和\n",
    "        sub_entropy += (prob) * tmp_entropy\n",
    "    print(\"iv:\",iv)\n",
    "    # 用父节点信息熵减去分类后子结点的权值信息熵总和，得出按某特征分类后的信息增益\n",
    "    rela_entropy = (get_entropy(dataset) - sub_entropy)/iv\n",
    "    return rela_entropy\n",
    "\n",
    "# 选取当前结点集合的最佳分类特征\n",
    "def select_feature(dataset, features):\n",
    "    rela_entropys = list()\n",
    "    \n",
    "    # 将每个特征的信息增益存储到列表中\n",
    "    for feature in features:\n",
    "        feature:int\n",
    "        rela_entropy = get_rela_entropy(dataset, feature)\n",
    "        rela_entropys.append(rela_entropy)\n",
    "        \n",
    "    # 返回最大信息增益的特征\n",
    "    return features[rela_entropys.index(max(rela_entropys))]\n",
    "\n",
    "# 返回当前结点的类别判定（判定为类中个数较多的）\n",
    "def major_label(labels):\n",
    "    \n",
    "    # 生成当前结点的类别集合\n",
    "    tags = list(set(labels))\n",
    "    tag_num = [sum([1 for i in labels if i==label]) for label in tags]\n",
    "    k = tag_num.index(max(tag_num))\n",
    "    \n",
    "    # 返回数量最多的类别\n",
    "    return tags[k]\n",
    "\n",
    "# 生成决策树，返回字典形式\n",
    "def build_tree(dataset, features) -> dict:\n",
    "    \n",
    "    \n",
    "    # 将当前结点的所有类别属性存入列表\n",
    "    labels = dataset[:, -1]\n",
    "    \n",
    "    # 第一种停止情况：当前结点属于同一类别则返回类别标记\n",
    "    if len(set(labels)) == 1:\n",
    "        return {'label': labels[0]}\n",
    "    \n",
    "    # 第二种情况：当前结点划分属性用完了\n",
    "    if not len(features):\n",
    "        return {'label': major_label(labels)}\n",
    "    \n",
    "    # 第三种情况：当前结点的所有属性取值相等\n",
    "    for feature in features:\n",
    "        f_tags = list(set(dataset[:, feature]))\n",
    "        if len(f_tags) == 1:\n",
    "            return {'label': major_label(labels)}\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # 选取根据信息增益选取最佳决策属性\n",
    "    best_feature = select_feature(dataset, features)\n",
    "    # print(\"best_feature:\",best_feature)\n",
    "    tree = {'feature': best_feature, 'children': {}}\n",
    "    \n",
    "    # 对该特征的每个取值进行决策划分\n",
    "    feature_tags = list(set(dataset[:, best_feature]))\n",
    "    for feature_tag in feature_tags:\n",
    "        sub_dataset = [d for d in dataset if d[best_feature]==feature_tag]\n",
    "        sub_dataset = np.array(sub_dataset)\n",
    "        \n",
    "        # 如果划分后的数据集为空，将其置为父结点类别\n",
    "        if len(sub_dataset) == 0:\n",
    "            tree['children'][feature_tag] = {'label_null': major_label(labels)}\n",
    "        else:\n",
    "            sub_features = [i for i in features if i != best_feature]\n",
    "            # print(\"sub_feature:\",sub_features)\n",
    "            tree['children'][feature_tag] = build_tree(sub_dataset, sub_features)\n",
    "    return tree\n",
    "\n",
    "def classify(tree:dict, sample):\n",
    "    for k, v in tree.items():\n",
    "        if k != 'feature':\n",
    "            return tree['label']\n",
    "        else:\n",
    "            return classify(tree['children'][sample[tree['feature']]], sample)\n",
    "\n",
    "        \n",
    "def classifier(tree:dict, features_data, default):\n",
    "    predict_vec = list()\n",
    "    for features_sample in features_data:\n",
    "        try:\n",
    "            predict = classify(tree, features_sample)\n",
    "        except KeyError:\n",
    "            predict = default\n",
    "        predict_vec.append(predict)\n",
    "    return predict_vec\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    train_data, test_data = load_data()\n",
    "    tree = build_tree(train_data, list(range(train_data.shape[1]-1)))\n",
    "    print(tree)\n",
    "    test_data_labels = test_data[:, -1]\n",
    "    test_data_features = test_data[:, :-1]\n",
    "    default = major_label(test_data_labels)\n",
    "    predict_vec = classifier(tree, test_data_features, default)\n",
    "    print(predict_vec)\n",
    "    accuracy = np.mean(np.array(predict_vec==test_data_labels))\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
