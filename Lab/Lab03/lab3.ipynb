{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 决策树构建算法\n",
    "- ID3（基于信息增益）\n",
    "- C4.5（基于信息增益比）\n",
    "- CART（gini指数）\n",
    "\n",
    "#### entropy：$H(x) = -\\sum_{i=1}^{n}p_i\\log{p_i}$\n",
    "\n",
    "#### conditional entropy: $H(Y|X)=\\sum{P(Xi)}H(Y|X=Xi)$\n",
    "\n",
    "#### information gain : $g(D, A)=H(D)-H(D|A)$\n",
    "\n",
    "#### information gain ratio: $g_R(D, A) = \\frac{g(D,A)}{H(A)}$\n",
    "\n",
    "#### gini index:$Gini(D)=\\sum_{k=1}^{K}p_k\\log{p_k}=1-\\sum_{k=1}^{K}p_k^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 在离散值上构建决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data():\n",
    "    datasets = [['青年', '否', '否', '一般', '否'],\n",
    "               ['青年', '否', '否', '好', '否'],\n",
    "               ['青年', '是', '否', '好', '是'],\n",
    "               ['青年', '是', '是', '一般', '是'],\n",
    "               ['青年', '否', '否', '一般', '否'],\n",
    "               ['中年', '否', '否', '一般', '否'],\n",
    "               ['中年', '否', '否', '好', '否'],\n",
    "               ['中年', '是', '是', '好', '是'],\n",
    "               ['中年', '否', '是', '非常好', '是'],\n",
    "               ['中年', '否', '是', '非常好', '是'],\n",
    "               ['老年', '否', '是', '非常好', '是'],\n",
    "               ['老年', '否', '是', '好', '是'],\n",
    "               ['老年', '是', '否', '好', '是'],\n",
    "               ['老年', '是', '否', '非常好', '是'],\n",
    "               ['老年', '否', '否', '一般', '否'],\n",
    "               ]\n",
    "    labels = [u'年龄', u'有工作', u'有自己的房子', u'信贷情况', u'类别']\n",
    "    # 返回数据集和每个维度的名称\n",
    "    return datasets, labels\n",
    "\n",
    "dataset, label = create_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['青年', '否', '否', '一般', '否'],\n",
       " ['青年', '否', '否', '好', '否'],\n",
       " ['青年', '是', '否', '好', '是'],\n",
       " ['青年', '是', '是', '一般', '是'],\n",
       " ['青年', '否', '否', '一般', '否'],\n",
       " ['中年', '否', '否', '一般', '否'],\n",
       " ['中年', '否', '否', '好', '否'],\n",
       " ['中年', '是', '是', '好', '是'],\n",
       " ['中年', '否', '是', '非常好', '是'],\n",
       " ['中年', '否', '是', '非常好', '是'],\n",
       " ['老年', '否', '是', '非常好', '是'],\n",
       " ['老年', '否', '是', '好', '是'],\n",
       " ['老年', '是', '否', '好', '是'],\n",
       " ['老年', '是', '否', '非常好', '是'],\n",
       " ['老年', '否', '否', '一般', '否']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['年龄', '有工作', '有自己的房子', '信贷情况', '类别']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>年龄</th>\n",
       "      <th>有工作</th>\n",
       "      <th>有自己的房子</th>\n",
       "      <th>信贷情况</th>\n",
       "      <th>类别</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>青年</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>一般</td>\n",
       "      <td>否</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>青年</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>好</td>\n",
       "      <td>否</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>青年</td>\n",
       "      <td>是</td>\n",
       "      <td>否</td>\n",
       "      <td>好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>青年</td>\n",
       "      <td>是</td>\n",
       "      <td>是</td>\n",
       "      <td>一般</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>青年</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>一般</td>\n",
       "      <td>否</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>中年</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>一般</td>\n",
       "      <td>否</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>中年</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>好</td>\n",
       "      <td>否</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>中年</td>\n",
       "      <td>是</td>\n",
       "      <td>是</td>\n",
       "      <td>好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>中年</td>\n",
       "      <td>否</td>\n",
       "      <td>是</td>\n",
       "      <td>非常好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>中年</td>\n",
       "      <td>否</td>\n",
       "      <td>是</td>\n",
       "      <td>非常好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>老年</td>\n",
       "      <td>否</td>\n",
       "      <td>是</td>\n",
       "      <td>非常好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>老年</td>\n",
       "      <td>否</td>\n",
       "      <td>是</td>\n",
       "      <td>好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>老年</td>\n",
       "      <td>是</td>\n",
       "      <td>否</td>\n",
       "      <td>好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>老年</td>\n",
       "      <td>是</td>\n",
       "      <td>否</td>\n",
       "      <td>非常好</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>老年</td>\n",
       "      <td>否</td>\n",
       "      <td>否</td>\n",
       "      <td>一般</td>\n",
       "      <td>否</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    年龄 有工作 有自己的房子 信贷情况 类别\n",
       "0   青年   否      否   一般  否\n",
       "1   青年   否      否    好  否\n",
       "2   青年   是      否    好  是\n",
       "3   青年   是      是   一般  是\n",
       "4   青年   否      否   一般  否\n",
       "5   中年   否      否   一般  否\n",
       "6   中年   否      否    好  否\n",
       "7   中年   是      是    好  是\n",
       "8   中年   否      是  非常好  是\n",
       "9   中年   否      是  非常好  是\n",
       "10  老年   否      是  非常好  是\n",
       "11  老年   否      是    好  是\n",
       "12  老年   是      否    好  是\n",
       "13  老年   是      否  非常好  是\n",
       "14  老年   否      否   一般  否"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dataset, columns=label)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### entropy：$H(x) = -\\sum_{i=1}^{n}p_i\\log{p_i}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cal_ent(dataset):\n",
    "    length = len(dataset)\n",
    "    values_dict = {}\n",
    "    for i in range(length):\n",
    "        label = dataset[i][-1]\n",
    "        if label not in values_dict:\n",
    "            values_dict[label] = 1\n",
    "        else:\n",
    "            values_dict[label] += 1\n",
    "    ent = -sum([(i/length)*math.log(i/length, 2) for i in values_dict.values()])\n",
    "    return ent\n",
    "\n",
    "cal_ent(np.array(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### conditional entropy: $H(Y|X)=\\sum{P(Xi)}H(Y|X=Xi)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8879430945988998"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cal_cond_ent(dataset, axis=0):\n",
    "    length = len(dataset)\n",
    "    feature_dict = {}\n",
    "    for i in range(length):\n",
    "        feature = dataset[i][axis]\n",
    "        if feature not in feature_dict:\n",
    "            feature_dict[feature] = []\n",
    "        feature_dict[feature].append(dataset[i])\n",
    "    cond_ent = sum([(len(p)/length)*cal_ent(p) for p in feature_dict.values()])\n",
    "    return cond_ent\n",
    "\n",
    "cal_cond_ent(np.array(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### information gain : $g(D, A)=H(D)-H(D|A)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08300749985576883"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def info_gain(ent, cond_ent):\n",
    "    return ent - cond_ent\n",
    "\n",
    "info_gain(cal_ent(np.array(dataset)), cal_cond_ent(np.array(dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### information gain ratio: $g_R(D, A) = \\frac{g(D,A)}{H(A)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.584962500721156"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cal_a_ent(dataset, axis=0):\n",
    "    # 计算D关于特征Ag的熵\n",
    "    length = len(dataset)\n",
    "    feature_dict = {}\n",
    "    for i in range(length):\n",
    "        feature = dataset[i][axis]\n",
    "        if feature not in feature_dict:\n",
    "            feature_dict[feature] = 0\n",
    "        feature_dict[feature] += 1\n",
    "    a_ent = -sum([(p/length)*math.log(p/length, 2) for p in feature_dict.values()])\n",
    "    return a_ent\n",
    "\n",
    "cal_a_ent(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05237190142858302"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def info_gain_ratio(dataset, axis=0):\n",
    "    # C4.5\n",
    "    ent = cal_ent(dataset)\n",
    "    cond_ent = cal_cond_ent(dataset, axis)\n",
    "    infogain = info_gain(ent, cond_ent)\n",
    "    a_ent = cal_a_ent(dataset, axis)\n",
    "    ratio = infogain / a_ent\n",
    "    return ratio\n",
    "\n",
    "info_gain_ratio(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 测试ID3算法的特征选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征0的信息增益是0.08300749985576883\n",
      "特征1的信息增益是0.32365019815155627\n",
      "特征2的信息增益是0.4199730940219749\n",
      "特征3的信息增益是0.36298956253708536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'特征2的信息增益最大，0.4199730940219749'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 给予最大信息增益选择特征进行划分\n",
    "def info_gain_train(dataset):\n",
    "    count = len(dataset[0]) - 1 # del label\n",
    "    ent = cal_ent(dataset)\n",
    "    info_gain_list = []\n",
    "    for c in range(count):\n",
    "        cond_ent = cal_cond_ent(dataset, c)\n",
    "        igain = info_gain(ent, cond_ent)\n",
    "        info_gain_list.append((c, igain))\n",
    "        print('特征{}的信息增益是{}'.format(c, igain))\n",
    "    \n",
    "    best = max(info_gain_list, key=lambda x: x[-1])\n",
    "    return '特征{}的信息增益最大，{}'.format(best[0], best[1])\n",
    "\n",
    "info_gain_train(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 测试C4.5算法的特征选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征0的信息增益率是0.05237190142858302\n",
      "特征1的信息增益率是0.3524465495205019\n",
      "特征2的信息增益率是0.4325380677663126\n",
      "特征3的信息增益率是0.23185388128724224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'特征2的信息增益率最大，0.4325380677663126'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def info_gain_ratio_train(dataset):\n",
    "    count = len(dataset[0]) - 1\n",
    "    info_gain_ratio_list = []\n",
    "    for c in range(count):\n",
    "        ratio = info_gain_ratio(dataset, c)\n",
    "        info_gain_ratio_list.append((c, ratio))\n",
    "        print('特征{}的信息增益率是{}'.format(c, ratio))\n",
    "    best = max(info_gain_ratio_list, key=lambda x: x[-1])\n",
    "    return '特征{}的信息增益率最大，{}'.format(best[0], best[1])\n",
    "        \n",
    "info_gain_ratio_train(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, leaf=True, label=None, feature_name=None, feature=None):\n",
    "        self.leaf = leaf # 是否是叶子结点\n",
    "        self.label = label # 类标签\n",
    "        self.feature_name = feature_name # 当前特征名\n",
    "        self.feature = feature # 当前特征索引\n",
    "        self.tree = {} # 子树\n",
    "        self.result = {'label': self.label, 'feature': self.feature, 'tree': self.tree}\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return '{}'.format(self.result)\n",
    "    \n",
    "    def add_node(self, val, node):\n",
    "        self.tree[val] = node\n",
    "        \n",
    "    def predict(self, features):\n",
    "        if self.leaf:\n",
    "            return self.label\n",
    "        # 递归查找\n",
    "        return self.tree[features[self.feature]].predict(features)\n",
    "    \n",
    "class DTree():\n",
    "    def __init__(self, epsilon=0.1, criterion='ID3'):\n",
    "        self.epsilon = epsilon\n",
    "        self.criterion = criterion\n",
    "        self._tree = {}\n",
    "    \n",
    "    @staticmethod\n",
    "    def cal_ent(dataset):\n",
    "        # 计算D的经验熵\n",
    "        length = len(dataset)\n",
    "        values_dict = {}\n",
    "        for i in range(length):\n",
    "            label = dataset[i][-1]\n",
    "            if label not in values_dict:\n",
    "                values_dict[label] = 1\n",
    "            else:\n",
    "                values_dict[label] += 1\n",
    "        ent = -sum([(i/length)*math.log(i/length, 2) for i in values_dict.values()])\n",
    "        return ent\n",
    "    \n",
    "    def cal_a_ent(dataset, axis=0):\n",
    "        # 计算D关于特征Ag的熵\n",
    "        length = len(dataset)\n",
    "        feature_dict = {}\n",
    "        for i in range(length):\n",
    "            feature = dataset[i][axis]\n",
    "            if feature not in feature_dict:\n",
    "                feature_dict[feature] = 0\n",
    "            feature_dict[feature] += 1\n",
    "        a_ent = -sum([(p/length)*math.log(p/length, 2) for p in feature_dict.values()])\n",
    "        return a_ent\n",
    "    \n",
    "    def cal_cond_ent(self, dataset, axis=0):\n",
    "        # 计算条件熵\n",
    "        length = len(dataset)\n",
    "        feature_dict = {}\n",
    "        for i in range(length):\n",
    "            feature = dataset[i][axis]\n",
    "            if feature not in feature_dict:\n",
    "                feature_dict[feature] = []\n",
    "            feature_dict[feature].append(dataset[i])\n",
    "        cond_ent = sum([(len(p)/length)*cal_ent(p) for p in feature_dict.values()])\n",
    "        return cond_ent\n",
    "    \n",
    "    @staticmethod\n",
    "    def info_gain(ent, cond_ent):\n",
    "        # 计算信息增益\n",
    "        return ent - cond_ent\n",
    "    \n",
    "    def info_gain_ratio(self, dataset, axis=0):\n",
    "        # C4.5\n",
    "        ent = self.cal_ent(dataset)\n",
    "        cond_ent = self.cal_cond_ent(dataset, axis)\n",
    "        info_gain = self.info_gain(ent, cond_ent)\n",
    "        a_ent = self.cal_a_ent(dataset, axis)\n",
    "        ratio = info_gain / a_ent\n",
    "        return ratio\n",
    "    \n",
    "    def info_gain_train(self, dataset):\n",
    "        # ID3\n",
    "        count = len(dataset[0]) - 1 # del label\n",
    "        ent = self.cal_ent(dataset)\n",
    "        info_gain_list = []\n",
    "        for c in range(count):\n",
    "            cond_ent = self.cal_cond_ent(dataset, c)\n",
    "            igain = self.info_gain(ent, cond_ent)\n",
    "            info_gain_list.append((c, igain))\n",
    "            # print('特征{}的信息增益是{}'.format(c, igain))\n",
    "        \n",
    "        # best: (索引，信息增益)\n",
    "        best = max(info_gain_list, key=lambda x: x[-1])\n",
    "        return best\n",
    "    \n",
    "    def info_gain_ratio_train(self, dataset):\n",
    "        # C4.5\n",
    "        count = len(dataset[0]) - 1\n",
    "        info_gain_ratio_list = []\n",
    "        for c in range(count):\n",
    "            ratio = info_gain_ratio(dataset, c)\n",
    "            info_gain_ratio_list.append((c, ratio))\n",
    "            # print('特征{}的信息增益率是{}'.format(c, ratio))\n",
    "        best = max(info_gain_ratio_list, key=lambda x: x[-1])\n",
    "        return best\n",
    "    \n",
    "    def train(self, train_data):\n",
    "        \"\"\"\n",
    "        train_data -- dataframe\n",
    "        \"\"\"\n",
    "        \n",
    "        x_train, y_train, features = train_data.iloc[:, :-1], train_data.iloc[:, -1], train_data.columns[:-1]\n",
    "        # 1. 若训练集数据属于同一个类别Ck，则将Ck作为类标记，建立单节点树T，返回T\n",
    "        if len(y_train.value_counts()) == 1:\n",
    "            return Node(leaf=True, label=y_train.iloc[0])\n",
    "        \n",
    "        # 2. 若特征集为空，则选择训练集中占比最大的类标签Ck作为节点的标记，建立单节点树T，返回T\n",
    "        if len(features) == 0:\n",
    "            return Node(leaf=True, label=y_train.value_counts().sort_values(ascending=False).index[0])\n",
    "        \n",
    "        # 3. 计算信息收益，选择信息受益最大的特征作为Ag\n",
    "        if self.criterion == 'ID3':\n",
    "            max_feature, max_info_gain = self.info_gain_train(np.array(train_data))\n",
    "            max_feature_name = features[max_feature]\n",
    "        if self.criterion == 'C4.5':\n",
    "            max_feature, max_info_gain = self.info_gain_ratio_train(np.array(train_data))\n",
    "            max_feature_name = features[max_feature]\n",
    "        \n",
    "        # 4. 如果Ag的信息增益小于epsilon，则停止决策，将训练集中类别数最大的类标签Ck作为标记，返回T\n",
    "        if max_info_gain < self.epsilon:\n",
    "            return Node(leaf=True, label=y_train.value_counts().sort_values(ascending=False).index[0])\n",
    "        \n",
    "        # 5. 以Ag进行划分，分别有特征类别棵子树\n",
    "        node_tree = Node(leaf=False, feature_name=max_feature_name, feature=max_feature)\n",
    "        feature_list = train_data[max_feature_name].value_counts().index.tolist()\n",
    "        \n",
    "        for f in feature_list:\n",
    "            sub_train_df = train_data.loc[train_data[max_feature_name] == f].drop([max_feature_name], axis=1)\n",
    "            \n",
    "            # 6. 递归生成子树\n",
    "            sub_tree = self.train(sub_train_df)\n",
    "            node_tree.add_node(f, sub_tree)\n",
    "        \n",
    "        return node_tree\n",
    "    \n",
    "    def fit(self, train_data):\n",
    "        self._tree = self.train(train_data)\n",
    "        return self._tree\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"预测单个样本的标签，X_test是单个样本\"\"\"\n",
    "        try:\n",
    "            return self._tree.predict(X_test) \n",
    "        except KeyError:\n",
    "            return None\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        \"\"\"计算预测正确率,\n",
    "        X -- array, shape=(m, n)\n",
    "        y -- array, shape=(m,)\n",
    "        \"\"\"\n",
    "        \n",
    "        correct = 0\n",
    "        for i in range(X.shape[0]):\n",
    "            x_use = X[i, :]\n",
    "            y_use = y[i]\n",
    "            y_pred = self.predict(x_use)\n",
    "            if y_pred is None:\n",
    "                continue\n",
    "            if y_pred == y_use:\n",
    "                correct += 1\n",
    "        return correct / X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 4) (5, 4) (10,) (5,)\n",
      "with criterion(ID3) the accuracy in train set is 1.000000\n",
      "with criterion(ID3) the accuracy in test set is 0.600000\n",
      "with criterion(C4.5) the accuracy in train set is 0.800000\n",
      "with criterion(C4.5) the accuracy in test set is 0.600000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "datasets, labels = create_data()\n",
    "data_df = pd.DataFrame(datasets, columns=labels)\n",
    "X_train, X_val, y_train, y_val = train_test_split(data_df.iloc[:, :-1], data_df.iloc[:, -1], test_size=0.3, random_state=0)\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)\n",
    "for c in ['ID3', 'C4.5']:\n",
    "    dt = DTree(criterion=c)\n",
    "    #tree = dt.fit(data_df)\n",
    "    tree = dt.fit(pd.concat([X_train, y_train], axis=1))\n",
    "    print('with criterion(%s) the accuracy in train set is %f' %(c, dt.score(X_train.values, y_train.values)))\n",
    "    print('with criterion(%s) the accuracy in test set is %f' %(c, dt.score(X_val.values, y_val.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data1():\n",
    "    data=[\n",
    "            ['young',   'myope',   'no',  'reduced',  'no lenses'],\n",
    "            ['young',   'myope',    'no',  'normal',  'soft'],\n",
    "            ['young',   'myope',   'yes', 'reduced', 'no lenses'],\n",
    "            ['young',   'myope',   'yes',  'normal',  'hard'],\n",
    "            ['young',   'hyper',   'no',  'reduced', 'no lenses'],\n",
    "            ['young',   'hyper',   'no',  'normal',  'soft'],\n",
    "            ['young',   'hyper',   'yes', 'reduced', 'no lenses'],\n",
    "            ['young',   'hyper',   'yes', 'normal',  'hard'],\n",
    "            ['pre',        'myope',   'no',  'reduced', 'no lenses'],\n",
    "            ['pre', 'myope',   'no',  'normal',  'soft'],\n",
    "            ['pre', 'myope',   'yes', 'reduced',  'no lenses'],\n",
    "            ['pre', 'myope',   'yes', 'normal',  'hard'],\n",
    "            ['pre', 'hyper',   'no',  'reduced', 'no lenses'],\n",
    "            ['pre', 'hyper',   'no',  'normal',  'soft'],\n",
    "            ['pre', 'hyper',   'yes', 'reduced', 'no lenses'],\n",
    "            ['pre', 'hyper',   'yes', 'normal',  'no lenses'],\n",
    "            ['presbyopic',  'myope',   'no',  'reduced', 'no lenses'],\n",
    "            ['presbyopic',  'myope',   'no',  'normal',  'no lenses'],\n",
    "            ['presbyopic',  'myope',   'yes', 'reduced', 'no lenses'],\n",
    "            ['presbyopic',  'myope',   'yes', 'normal',  'hard'],\n",
    "            ['presbyopic',  'hyper',   'no',  'reduced', 'no lenses'],\n",
    "            ['presbyopic',  'hyper',   'no',  'normal',  'soft'],\n",
    "            ['presbyopic',  'hyper',   'yes', 'reduced', 'no lenses'],\n",
    "            ['presbyopic',  'hyper',   'yes', 'normal',  'no lenses']\n",
    "            ]\n",
    "\n",
    "    labels = ['age', 'prescript', 'stigmatic', 'tearRate', 'target']\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 4) (10, 4) (14,) (10,)\n",
      "with criterion(ID3) the accuracy in train set is 0.857143\n",
      "with criterion(ID3) the accuracy in test set is 0.800000\n",
      "with criterion(C4.5) the accuracy in train set is 1.000000\n",
      "with criterion(C4.5) the accuracy in test set is 0.700000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "datasets, labels = create_data1()\n",
    "data_df = pd.DataFrame(datasets, columns=labels)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(data_df.iloc[:, :-1], data_df.iloc[:, -1], test_size=0.4, random_state=0)\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)\n",
    "for c in ['ID3', 'C4.5']:\n",
    "    dt = DTree(criterion=c)\n",
    "    tree = dt.fit(pd.concat([X_train, y_train], axis=1))\n",
    "    #print(tree)\n",
    "    print('with criterion(%s) the accuracy in train set is %f' %(c, dt.score(X_train.values, y_train.values)))\n",
    "    print('with criterion(%s) the accuracy in test set is %f' %(c, dt.score(X_val.values, y_val.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "dt = DTree()\n",
    "tree = dt.fit(data_df)\n",
    "print(dt.score(data_df.values[:, :-1], data_df.values[:, -1]))\n",
    "for i in range(data_df.shape[0]):\n",
    "    print(dt.predict(data_df.iloc[i].values))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. iris分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': '/Users/zhujun/anaconda3/lib/python3.6/site-packages/sklearn/datasets/data/iris.csv'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "data = datasets.load_iris()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data['data']\n",
    "y = data['target']\n",
    "columns = data['feature_names']\n",
    "labels = data['target_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4) (150,) ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'] ['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print(x.shape, y.shape, columns, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([50, 50, 50])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 说明类别平衡\n",
    "np.bincount(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 sklearn decisiontree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn decision tree trainset accuracy:  1.0\n",
      "sklearn decision tree testset accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(x_train, y_train)\n",
    "print('sklearn decision tree trainset accuracy: ', dtc.score(x_train, y_train))\n",
    "print('sklearn decision tree testset accuracy: ', dtc.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 4) (45, 4) (105,) (45,)\n",
      "[0.37142857142857144, 0.9714285714285714, 1.0, 1.0, 1.0, 1.0, 0.37142857142857144, 0.37142857142857144, 0.37142857142857144, 0.9904761904761905, 1.0, 1.0]\n",
      "[0.24444444444444444, 0.8, 0.7333333333333333, 0.7333333333333333, 0.7333333333333333, 0.7333333333333333, 0.24444444444444444, 0.24444444444444444, 0.24444444444444444, 0.8888888888888888, 0.8444444444444444, 0.8444444444444444]\n"
     ]
    }
   ],
   "source": [
    "data_df = pd.DataFrame(np.hstack((x, np.expand_dims(y, axis=-1))), columns=columns+['traget'])\n",
    "X_train, X_val, y_train, y_val = train_test_split(data_df.iloc[:, :-1], data_df.iloc[:, -1], test_size=0.3, random_state=0)\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)\n",
    "train_score, test_score = [], []\n",
    "features = []\n",
    "for c in ['ID3', 'C4.5']:\n",
    "    for e in [5, 1, 0.6, 0.3, 0.1, 0.01]:\n",
    "        features.append((c, e))\n",
    "for c, e in features:\n",
    "    dt = DTree(criterion=c, epsilon=e)\n",
    "    tree = dt.fit(pd.concat([X_train, y_train], axis=1))\n",
    "    #print('with criterion(%s) and epsilon(%f) the accuracy in train set is %f' %(c, e, dt.score(X_train.values, y_train.values)))\n",
    "    train_score.append(dt.score(X_train.values, y_train.values))\n",
    "    test_score.append(dt.score(X_val.values, y_val.values))\n",
    "    #print('with criterion(%s) and epsilon(%f) the accuracy in test set is %f' %(c, e, dt.score(X_val.values, y_val.values)))\n",
    "print(train_score)\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "trains = np.array(train_score)\n",
    "tests = np.array(test_score)\n",
    "# np.hstack((trains, tests)).reshape(4, 5).T\n",
    "result = pd.DataFrame(np.hstack((trains, tests)).reshape(4, 6).T, columns=['train_ID3', 'train_C4.5', 'test_ID3', 'test_C4.5'], index=[5, 1, 0.6, 0.3, 0.1, 0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_ID3</th>\n",
       "      <th>train_C4.5</th>\n",
       "      <th>test_ID3</th>\n",
       "      <th>test_C4.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5.00</th>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>0.244444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.244444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.60</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.244444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.30</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990476</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.844444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.01</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.844444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      train_ID3  train_C4.5  test_ID3  test_C4.5\n",
       "5.00   0.371429    0.371429  0.244444   0.244444\n",
       "1.00   0.971429    0.371429  0.800000   0.244444\n",
       "0.60   1.000000    0.371429  0.733333   0.244444\n",
       "0.30   1.000000    0.990476  0.733333   0.888889\n",
       "0.10   1.000000    1.000000  0.733333   0.844444\n",
       "0.01   1.000000    1.000000  0.733333   0.844444"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_ID3</th>\n",
       "      <th>test_ID3</th>\n",
       "      <th>train_C4.5</th>\n",
       "      <th>test_C4.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5.00</th>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.244444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.244444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.60</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.244444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.30</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.990476</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.844444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.01</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.844444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      train_ID3  test_ID3  train_C4.5  test_C4.5\n",
       "5.00   0.371429  0.244444    0.371429   0.244444\n",
       "1.00   0.971429  0.800000    0.371429   0.244444\n",
       "0.60   1.000000  0.733333    0.371429   0.244444\n",
       "0.30   1.000000  0.733333    0.990476   0.888889\n",
       "0.10   1.000000  0.733333    1.000000   0.844444\n",
       "0.01   1.000000  0.733333    1.000000   0.844444"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.reindex(columns=['train_ID3', 'test_ID3', 'train_C4.5', 'test_C4.5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
